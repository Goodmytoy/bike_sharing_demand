{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "CAT_FEATURES = [\n",
    "    \"area_type\",\n",
    "    \"city\",\n",
    "    \"furnishing_status\",\n",
    "    \"tenant_preferred\",\n",
    "    \"point_of_contact\",\n",
    "]\n",
    "\n",
    "\n",
    "def extract_floor(floor_info: str) -> int:\n",
    "    \"\"\"층수 컬럼에서 실제 층수만 추출합니다.\n",
    "\n",
    "    현재 층수 정보는 'X out of Y'로 되어 있습니다.\n",
    "    여기에서 X만 추출하여 정수로 반환합니다.\n",
    "    Upper basement, Lower basement, Ground out 등은 모두 0층으로 변환합니다.\n",
    "\n",
    "    Args:\n",
    "        floor_info (str): 층수 정보\n",
    "    \"\"\"\n",
    "    split_floor_info = floor_info.split()\n",
    "    floor_str = split_floor_info[0]\n",
    "\n",
    "    return int(floor_str) if floor_str.isnumeric() else 0\n",
    "\n",
    "\n",
    "# extract_floor()가 str -> int라서, 이걸 감싸는 Wrapping function임\n",
    "\n",
    "\n",
    "def floor_extractor(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "    \"\"\"`extract_floor()` 함수를 `FunctionTransformer`에 사용하기 위한\n",
    "    Wrapping function입니다.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 데이터프레임\n",
    "        col (str): `extract_floor()`를 적용할 컬럼명\n",
    "            `Floor`만 사용해야 함\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 컬럼 처리 후 데이터\n",
    "    \"\"\"\n",
    "    df[col] = df[col].apply(lambda x: extract_floor(x))\n",
    "    return df\n",
    "\n",
    "\n",
    "# 전처리 파이프라인 작성\n",
    "# 1. 방의 크기는 제곱근을 적용함 (FunctionTransformer 사용)\n",
    "# 2. 층수는 실제 층수를 추출하되 숫자가 아닌 Basement 등은 0층으로 표기함\n",
    "# 3. 범주형 변수(CAT_FEATURES)는 타겟 인코딩 적용 (from category_encoders import TargetEncoder)\n",
    "# ColumnTransform 으로 만드는 객체에는 Transform이 무조건 존재함. fit은 있을 수도 있고, 없을 수도 있음\n",
    "\n",
    "preprocess_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"sqrt_transformer\", FunctionTransformer(np.sqrt), [\"size\"]),\n",
    "        (\n",
    "            \"floor_extractor\",\n",
    "            FunctionTransformer(floor_extractor, kw_args={\"col\": \"floor\"}),\n",
    "            [\"floor\"],\n",
    "        ),\n",
    "        (\"target_encoder\", TargetEncoder(cols=CAT_FEATURES), CAT_FEATURES),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "preprocess_pipeline.set_output(transform=\"pandas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.common.constants import ARTIFACT_PATH, DATA_PATH, LOG_FILEPATH\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, \"bike_sharing_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['datetime'] = pd.to_datetime(train_df['datetime'])\n",
    "\n",
    "train_df['year'] = train_df['datetime'].dt.year\n",
    "train_df['month'] = train_df['datetime'].dt.month\n",
    "train_df['hour'] = train_df['datetime'].dt.hour\n",
    "train_df['weekday'] = train_df['datetime'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5422 entries, 0 to 5421\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   datetime    5422 non-null   datetime64[ns]\n",
      " 1   season      5422 non-null   int64         \n",
      " 2   holiday     5422 non-null   int64         \n",
      " 3   workingday  5422 non-null   int64         \n",
      " 4   weather     5422 non-null   int64         \n",
      " 5   temp        5422 non-null   float64       \n",
      " 6   atemp       5422 non-null   float64       \n",
      " 7   humidity    5422 non-null   int64         \n",
      " 8   windspeed   5422 non-null   float64       \n",
      " 9   count       5422 non-null   int64         \n",
      " 10  year        5422 non-null   int32         \n",
      " 11  month       5422 non-null   int32         \n",
      " 12  hour        5422 non-null   int32         \n",
      " 13  weekday     5422 non-null   int32         \n",
      "dtypes: datetime64[ns](1), float64(3), int32(4), int64(6)\n",
      "memory usage: 508.4 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = 'datetime'\n",
    "train_df = train_df.drop(drop_features, axis=1)\n",
    "#train_df.to_csv(os.path.join(DATA_PATH, \"bike_sharing_train_22.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
